// This file was automatically generated by genny.
// Any changes will be lost if this file is regenerated.
// see https://github.com/cheekybits/genny

package colony

import (
	"sync"
	"unsafe"

	"github.com/willf/bitset"
)

type BoolColony struct {
	entry *colonyGroupbool
}

// NewBoolColony returns a new colony of ValueBool's.
func NewBoolColony() *BoolColony {
	return &BoolColony{
		entry: newboolGroup(nil),
	}
}

// Iterate sends pointers to all instances of ValueBool in the colony to the given channel.
func (c *BoolColony) Iterate() <-chan *bool {
	ch := make(chan *bool)
	var wg sync.WaitGroup
	for g := c.entry; g != nil; g = g.next {
		wg.Add(1)
		go func(g *colonyGroupbool) {
			g.l.RLock()
			for i, e := g.index.NextSet(0); e; i, e = g.index.NextSet(i + 1) {
				ch <- &g.data[i]
			}
			g.l.RUnlock()
			wg.Done()
		}(g)
	}
	go func() {
		wg.Wait()
		close(ch)
	}()
	return ch
}

func (c *BoolColony) Insert(t *bool) (tp *bool) {
	return c.entry.Insert(t)
}

func (c *BoolColony) Delete(tp *bool) {
	c.entry.Delete(tp)
}

func newboolGroup(previous *colonyGroupbool) *colonyGroupbool {
	var g colonyGroupbool
	if previous != nil {
		g.data = make([]bool, len(previous.data)*2)
		g.index = bitset.New(uint(len(previous.data) * 2))
	} else {
		g.data = make([]bool, 8)
		g.index = bitset.New(8)
	}
	g.next = nil
	g.l = &sync.RWMutex{}
	g.minPtr = uintptr(unsafe.Pointer(&g.data[0]))
	g.maxPtr = uintptr(unsafe.Pointer(&g.data[len(g.data)-1]))
	return &g
}

type colonyGroupbool struct {
	data     []bool
	index    *bitset.BitSet
	maxPtr   uintptr
	minPtr   uintptr
	next     *colonyGroupbool
	previous *colonyGroupbool

	l *sync.RWMutex
}

func (g *colonyGroupbool) Insert(t *bool) (tp *bool) {
	g.l.Lock()
	if i, e := g.index.NextClear(0); e {
		g.data[i] = *t
		g.index.Set(i)
		tp = &g.data[i]
		g.l.Unlock()
		return
	}
	if g.next == nil {
		g.next = newboolGroup(g)
	}
	g.l.Unlock()
	return g.next.Insert(t)
}

func (g *colonyGroupbool) Delete(tp *bool) {
	if uintptr(unsafe.Pointer(tp)) > g.maxPtr { // hack to determine if a pointer points to this array
		g.next.Delete(tp)
	}
	g.l.Lock()
	for i := 0; i < len(g.data); i++ {
		if tp == &g.data[i] {
			g.index.Clear(uint(i))
			//if !g.index.Any() {
			// TODO: if a group has no more elements, then we should de-allocate it.
			//}
			g.l.Unlock()
			return
		}
	}
	g.l.Unlock()
	if g.next != nil {
		g.next.Delete(tp)
	}
}

type ByteColony struct {
	entry *colonyGroupbyte
}

// NewByteColony returns a new colony of ValueByte's.
func NewByteColony() *ByteColony {
	return &ByteColony{
		entry: newbyteGroup(nil),
	}
}

// Iterate sends pointers to all instances of ValueByte in the colony to the given channel.
func (c *ByteColony) Iterate() <-chan *byte {
	ch := make(chan *byte)
	var wg sync.WaitGroup
	for g := c.entry; g != nil; g = g.next {
		wg.Add(1)
		go func(g *colonyGroupbyte) {
			g.l.RLock()
			for i, e := g.index.NextSet(0); e; i, e = g.index.NextSet(i + 1) {
				ch <- &g.data[i]
			}
			g.l.RUnlock()
			wg.Done()
		}(g)
	}
	go func() {
		wg.Wait()
		close(ch)
	}()
	return ch
}

func (c *ByteColony) Insert(t *byte) (tp *byte) {
	return c.entry.Insert(t)
}

func (c *ByteColony) Delete(tp *byte) {
	c.entry.Delete(tp)
}

func newbyteGroup(previous *colonyGroupbyte) *colonyGroupbyte {
	var g colonyGroupbyte
	if previous != nil {
		g.data = make([]byte, len(previous.data)*2)
		g.index = bitset.New(uint(len(previous.data) * 2))
	} else {
		g.data = make([]byte, 8)
		g.index = bitset.New(8)
	}
	g.next = nil
	g.l = &sync.RWMutex{}
	g.minPtr = uintptr(unsafe.Pointer(&g.data[0]))
	g.maxPtr = uintptr(unsafe.Pointer(&g.data[len(g.data)-1]))
	return &g
}

type colonyGroupbyte struct {
	data     []byte
	index    *bitset.BitSet
	maxPtr   uintptr
	minPtr   uintptr
	next     *colonyGroupbyte
	previous *colonyGroupbyte

	l *sync.RWMutex
}

func (g *colonyGroupbyte) Insert(t *byte) (tp *byte) {
	g.l.Lock()
	if i, e := g.index.NextClear(0); e {
		g.data[i] = *t
		g.index.Set(i)
		tp = &g.data[i]
		g.l.Unlock()
		return
	}
	if g.next == nil {
		g.next = newbyteGroup(g)
	}
	g.l.Unlock()
	return g.next.Insert(t)
}

func (g *colonyGroupbyte) Delete(tp *byte) {
	if uintptr(unsafe.Pointer(tp)) > g.maxPtr { // hack to determine if a pointer points to this array
		g.next.Delete(tp)
	}
	g.l.Lock()
	for i := 0; i < len(g.data); i++ {
		if tp == &g.data[i] {
			g.index.Clear(uint(i))
			//if !g.index.Any() {
			// TODO: if a group has no more elements, then we should de-allocate it.
			//}
			g.l.Unlock()
			return
		}
	}
	g.l.Unlock()
	if g.next != nil {
		g.next.Delete(tp)
	}
}

type Complex128Colony struct {
	entry *colonyGroupcomplex128
}

// NewComplex128Colony returns a new colony of ValueComplex128's.
func NewComplex128Colony() *Complex128Colony {
	return &Complex128Colony{
		entry: newcomplex128Group(nil),
	}
}

// Iterate sends pointers to all instances of ValueComplex128 in the colony to the given channel.
func (c *Complex128Colony) Iterate() <-chan *complex128 {
	ch := make(chan *complex128)
	var wg sync.WaitGroup
	for g := c.entry; g != nil; g = g.next {
		wg.Add(1)
		go func(g *colonyGroupcomplex128) {
			g.l.RLock()
			for i, e := g.index.NextSet(0); e; i, e = g.index.NextSet(i + 1) {
				ch <- &g.data[i]
			}
			g.l.RUnlock()
			wg.Done()
		}(g)
	}
	go func() {
		wg.Wait()
		close(ch)
	}()
	return ch
}

func (c *Complex128Colony) Insert(t *complex128) (tp *complex128) {
	return c.entry.Insert(t)
}

func (c *Complex128Colony) Delete(tp *complex128) {
	c.entry.Delete(tp)
}

func newcomplex128Group(previous *colonyGroupcomplex128) *colonyGroupcomplex128 {
	var g colonyGroupcomplex128
	if previous != nil {
		g.data = make([]complex128, len(previous.data)*2)
		g.index = bitset.New(uint(len(previous.data) * 2))
	} else {
		g.data = make([]complex128, 8)
		g.index = bitset.New(8)
	}
	g.next = nil
	g.l = &sync.RWMutex{}
	g.minPtr = uintptr(unsafe.Pointer(&g.data[0]))
	g.maxPtr = uintptr(unsafe.Pointer(&g.data[len(g.data)-1]))
	return &g
}

type colonyGroupcomplex128 struct {
	data     []complex128
	index    *bitset.BitSet
	maxPtr   uintptr
	minPtr   uintptr
	next     *colonyGroupcomplex128
	previous *colonyGroupcomplex128

	l *sync.RWMutex
}

func (g *colonyGroupcomplex128) Insert(t *complex128) (tp *complex128) {
	g.l.Lock()
	if i, e := g.index.NextClear(0); e {
		g.data[i] = *t
		g.index.Set(i)
		tp = &g.data[i]
		g.l.Unlock()
		return
	}
	if g.next == nil {
		g.next = newcomplex128Group(g)
	}
	g.l.Unlock()
	return g.next.Insert(t)
}

func (g *colonyGroupcomplex128) Delete(tp *complex128) {
	if uintptr(unsafe.Pointer(tp)) > g.maxPtr { // hack to determine if a pointer points to this array
		g.next.Delete(tp)
	}
	g.l.Lock()
	for i := 0; i < len(g.data); i++ {
		if tp == &g.data[i] {
			g.index.Clear(uint(i))
			//if !g.index.Any() {
			// TODO: if a group has no more elements, then we should de-allocate it.
			//}
			g.l.Unlock()
			return
		}
	}
	g.l.Unlock()
	if g.next != nil {
		g.next.Delete(tp)
	}
}

type Complex64Colony struct {
	entry *colonyGroupcomplex64
}

// NewComplex64Colony returns a new colony of ValueComplex64's.
func NewComplex64Colony() *Complex64Colony {
	return &Complex64Colony{
		entry: newcomplex64Group(nil),
	}
}

// Iterate sends pointers to all instances of ValueComplex64 in the colony to the given channel.
func (c *Complex64Colony) Iterate() <-chan *complex64 {
	ch := make(chan *complex64)
	var wg sync.WaitGroup
	for g := c.entry; g != nil; g = g.next {
		wg.Add(1)
		go func(g *colonyGroupcomplex64) {
			g.l.RLock()
			for i, e := g.index.NextSet(0); e; i, e = g.index.NextSet(i + 1) {
				ch <- &g.data[i]
			}
			g.l.RUnlock()
			wg.Done()
		}(g)
	}
	go func() {
		wg.Wait()
		close(ch)
	}()
	return ch
}

func (c *Complex64Colony) Insert(t *complex64) (tp *complex64) {
	return c.entry.Insert(t)
}

func (c *Complex64Colony) Delete(tp *complex64) {
	c.entry.Delete(tp)
}

func newcomplex64Group(previous *colonyGroupcomplex64) *colonyGroupcomplex64 {
	var g colonyGroupcomplex64
	if previous != nil {
		g.data = make([]complex64, len(previous.data)*2)
		g.index = bitset.New(uint(len(previous.data) * 2))
	} else {
		g.data = make([]complex64, 8)
		g.index = bitset.New(8)
	}
	g.next = nil
	g.l = &sync.RWMutex{}
	g.minPtr = uintptr(unsafe.Pointer(&g.data[0]))
	g.maxPtr = uintptr(unsafe.Pointer(&g.data[len(g.data)-1]))
	return &g
}

type colonyGroupcomplex64 struct {
	data     []complex64
	index    *bitset.BitSet
	maxPtr   uintptr
	minPtr   uintptr
	next     *colonyGroupcomplex64
	previous *colonyGroupcomplex64

	l *sync.RWMutex
}

func (g *colonyGroupcomplex64) Insert(t *complex64) (tp *complex64) {
	g.l.Lock()
	if i, e := g.index.NextClear(0); e {
		g.data[i] = *t
		g.index.Set(i)
		tp = &g.data[i]
		g.l.Unlock()
		return
	}
	if g.next == nil {
		g.next = newcomplex64Group(g)
	}
	g.l.Unlock()
	return g.next.Insert(t)
}

func (g *colonyGroupcomplex64) Delete(tp *complex64) {
	if uintptr(unsafe.Pointer(tp)) > g.maxPtr { // hack to determine if a pointer points to this array
		g.next.Delete(tp)
	}
	g.l.Lock()
	for i := 0; i < len(g.data); i++ {
		if tp == &g.data[i] {
			g.index.Clear(uint(i))
			//if !g.index.Any() {
			// TODO: if a group has no more elements, then we should de-allocate it.
			//}
			g.l.Unlock()
			return
		}
	}
	g.l.Unlock()
	if g.next != nil {
		g.next.Delete(tp)
	}
}

type ErrorColony struct {
	entry *colonyGrouperror
}

// NewErrorColony returns a new colony of ValueError's.
func NewErrorColony() *ErrorColony {
	return &ErrorColony{
		entry: newerrorGroup(nil),
	}
}

// Iterate sends pointers to all instances of ValueError in the colony to the given channel.
func (c *ErrorColony) Iterate() <-chan *error {
	ch := make(chan *error)
	var wg sync.WaitGroup
	for g := c.entry; g != nil; g = g.next {
		wg.Add(1)
		go func(g *colonyGrouperror) {
			g.l.RLock()
			for i, e := g.index.NextSet(0); e; i, e = g.index.NextSet(i + 1) {
				ch <- &g.data[i]
			}
			g.l.RUnlock()
			wg.Done()
		}(g)
	}
	go func() {
		wg.Wait()
		close(ch)
	}()
	return ch
}

func (c *ErrorColony) Insert(t *error) (tp *error) {
	return c.entry.Insert(t)
}

func (c *ErrorColony) Delete(tp *error) {
	c.entry.Delete(tp)
}

func newerrorGroup(previous *colonyGrouperror) *colonyGrouperror {
	var g colonyGrouperror
	if previous != nil {
		g.data = make([]error, len(previous.data)*2)
		g.index = bitset.New(uint(len(previous.data) * 2))
	} else {
		g.data = make([]error, 8)
		g.index = bitset.New(8)
	}
	g.next = nil
	g.l = &sync.RWMutex{}
	g.minPtr = uintptr(unsafe.Pointer(&g.data[0]))
	g.maxPtr = uintptr(unsafe.Pointer(&g.data[len(g.data)-1]))
	return &g
}

type colonyGrouperror struct {
	data     []error
	index    *bitset.BitSet
	maxPtr   uintptr
	minPtr   uintptr
	next     *colonyGrouperror
	previous *colonyGrouperror

	l *sync.RWMutex
}

func (g *colonyGrouperror) Insert(t *error) (tp *error) {
	g.l.Lock()
	if i, e := g.index.NextClear(0); e {
		g.data[i] = *t
		g.index.Set(i)
		tp = &g.data[i]
		g.l.Unlock()
		return
	}
	if g.next == nil {
		g.next = newerrorGroup(g)
	}
	g.l.Unlock()
	return g.next.Insert(t)
}

func (g *colonyGrouperror) Delete(tp *error) {
	if uintptr(unsafe.Pointer(tp)) > g.maxPtr { // hack to determine if a pointer points to this array
		g.next.Delete(tp)
	}
	g.l.Lock()
	for i := 0; i < len(g.data); i++ {
		if tp == &g.data[i] {
			g.index.Clear(uint(i))
			//if !g.index.Any() {
			// TODO: if a group has no more elements, then we should de-allocate it.
			//}
			g.l.Unlock()
			return
		}
	}
	g.l.Unlock()
	if g.next != nil {
		g.next.Delete(tp)
	}
}

type Float32Colony struct {
	entry *colonyGroupfloat32
}

// NewFloat32Colony returns a new colony of ValueFloat32's.
func NewFloat32Colony() *Float32Colony {
	return &Float32Colony{
		entry: newfloat32Group(nil),
	}
}

// Iterate sends pointers to all instances of ValueFloat32 in the colony to the given channel.
func (c *Float32Colony) Iterate() <-chan *float32 {
	ch := make(chan *float32)
	var wg sync.WaitGroup
	for g := c.entry; g != nil; g = g.next {
		wg.Add(1)
		go func(g *colonyGroupfloat32) {
			g.l.RLock()
			for i, e := g.index.NextSet(0); e; i, e = g.index.NextSet(i + 1) {
				ch <- &g.data[i]
			}
			g.l.RUnlock()
			wg.Done()
		}(g)
	}
	go func() {
		wg.Wait()
		close(ch)
	}()
	return ch
}

func (c *Float32Colony) Insert(t *float32) (tp *float32) {
	return c.entry.Insert(t)
}

func (c *Float32Colony) Delete(tp *float32) {
	c.entry.Delete(tp)
}

func newfloat32Group(previous *colonyGroupfloat32) *colonyGroupfloat32 {
	var g colonyGroupfloat32
	if previous != nil {
		g.data = make([]float32, len(previous.data)*2)
		g.index = bitset.New(uint(len(previous.data) * 2))
	} else {
		g.data = make([]float32, 8)
		g.index = bitset.New(8)
	}
	g.next = nil
	g.l = &sync.RWMutex{}
	g.minPtr = uintptr(unsafe.Pointer(&g.data[0]))
	g.maxPtr = uintptr(unsafe.Pointer(&g.data[len(g.data)-1]))
	return &g
}

type colonyGroupfloat32 struct {
	data     []float32
	index    *bitset.BitSet
	maxPtr   uintptr
	minPtr   uintptr
	next     *colonyGroupfloat32
	previous *colonyGroupfloat32

	l *sync.RWMutex
}

func (g *colonyGroupfloat32) Insert(t *float32) (tp *float32) {
	g.l.Lock()
	if i, e := g.index.NextClear(0); e {
		g.data[i] = *t
		g.index.Set(i)
		tp = &g.data[i]
		g.l.Unlock()
		return
	}
	if g.next == nil {
		g.next = newfloat32Group(g)
	}
	g.l.Unlock()
	return g.next.Insert(t)
}

func (g *colonyGroupfloat32) Delete(tp *float32) {
	if uintptr(unsafe.Pointer(tp)) > g.maxPtr { // hack to determine if a pointer points to this array
		g.next.Delete(tp)
	}
	g.l.Lock()
	for i := 0; i < len(g.data); i++ {
		if tp == &g.data[i] {
			g.index.Clear(uint(i))
			//if !g.index.Any() {
			// TODO: if a group has no more elements, then we should de-allocate it.
			//}
			g.l.Unlock()
			return
		}
	}
	g.l.Unlock()
	if g.next != nil {
		g.next.Delete(tp)
	}
}

type Float64Colony struct {
	entry *colonyGroupfloat64
}

// NewFloat64Colony returns a new colony of ValueFloat64's.
func NewFloat64Colony() *Float64Colony {
	return &Float64Colony{
		entry: newfloat64Group(nil),
	}
}

// Iterate sends pointers to all instances of ValueFloat64 in the colony to the given channel.
func (c *Float64Colony) Iterate() <-chan *float64 {
	ch := make(chan *float64)
	var wg sync.WaitGroup
	for g := c.entry; g != nil; g = g.next {
		wg.Add(1)
		go func(g *colonyGroupfloat64) {
			g.l.RLock()
			for i, e := g.index.NextSet(0); e; i, e = g.index.NextSet(i + 1) {
				ch <- &g.data[i]
			}
			g.l.RUnlock()
			wg.Done()
		}(g)
	}
	go func() {
		wg.Wait()
		close(ch)
	}()
	return ch
}

func (c *Float64Colony) Insert(t *float64) (tp *float64) {
	return c.entry.Insert(t)
}

func (c *Float64Colony) Delete(tp *float64) {
	c.entry.Delete(tp)
}

func newfloat64Group(previous *colonyGroupfloat64) *colonyGroupfloat64 {
	var g colonyGroupfloat64
	if previous != nil {
		g.data = make([]float64, len(previous.data)*2)
		g.index = bitset.New(uint(len(previous.data) * 2))
	} else {
		g.data = make([]float64, 8)
		g.index = bitset.New(8)
	}
	g.next = nil
	g.l = &sync.RWMutex{}
	g.minPtr = uintptr(unsafe.Pointer(&g.data[0]))
	g.maxPtr = uintptr(unsafe.Pointer(&g.data[len(g.data)-1]))
	return &g
}

type colonyGroupfloat64 struct {
	data     []float64
	index    *bitset.BitSet
	maxPtr   uintptr
	minPtr   uintptr
	next     *colonyGroupfloat64
	previous *colonyGroupfloat64

	l *sync.RWMutex
}

func (g *colonyGroupfloat64) Insert(t *float64) (tp *float64) {
	g.l.Lock()
	if i, e := g.index.NextClear(0); e {
		g.data[i] = *t
		g.index.Set(i)
		tp = &g.data[i]
		g.l.Unlock()
		return
	}
	if g.next == nil {
		g.next = newfloat64Group(g)
	}
	g.l.Unlock()
	return g.next.Insert(t)
}

func (g *colonyGroupfloat64) Delete(tp *float64) {
	if uintptr(unsafe.Pointer(tp)) > g.maxPtr { // hack to determine if a pointer points to this array
		g.next.Delete(tp)
	}
	g.l.Lock()
	for i := 0; i < len(g.data); i++ {
		if tp == &g.data[i] {
			g.index.Clear(uint(i))
			//if !g.index.Any() {
			// TODO: if a group has no more elements, then we should de-allocate it.
			//}
			g.l.Unlock()
			return
		}
	}
	g.l.Unlock()
	if g.next != nil {
		g.next.Delete(tp)
	}
}

type IntColony struct {
	entry *colonyGroupint
}

// NewIntColony returns a new colony of ValueInt's.
func NewIntColony() *IntColony {
	return &IntColony{
		entry: newintGroup(nil),
	}
}

// Iterate sends pointers to all instances of ValueInt in the colony to the given channel.
func (c *IntColony) Iterate() <-chan *int {
	ch := make(chan *int)
	var wg sync.WaitGroup
	for g := c.entry; g != nil; g = g.next {
		wg.Add(1)
		go func(g *colonyGroupint) {
			g.l.RLock()
			for i, e := g.index.NextSet(0); e; i, e = g.index.NextSet(i + 1) {
				ch <- &g.data[i]
			}
			g.l.RUnlock()
			wg.Done()
		}(g)
	}
	go func() {
		wg.Wait()
		close(ch)
	}()
	return ch
}

func (c *IntColony) Insert(t *int) (tp *int) {
	return c.entry.Insert(t)
}

func (c *IntColony) Delete(tp *int) {
	c.entry.Delete(tp)
}

func newintGroup(previous *colonyGroupint) *colonyGroupint {
	var g colonyGroupint
	if previous != nil {
		g.data = make([]int, len(previous.data)*2)
		g.index = bitset.New(uint(len(previous.data) * 2))
	} else {
		g.data = make([]int, 8)
		g.index = bitset.New(8)
	}
	g.next = nil
	g.l = &sync.RWMutex{}
	g.minPtr = uintptr(unsafe.Pointer(&g.data[0]))
	g.maxPtr = uintptr(unsafe.Pointer(&g.data[len(g.data)-1]))
	return &g
}

type colonyGroupint struct {
	data     []int
	index    *bitset.BitSet
	maxPtr   uintptr
	minPtr   uintptr
	next     *colonyGroupint
	previous *colonyGroupint

	l *sync.RWMutex
}

func (g *colonyGroupint) Insert(t *int) (tp *int) {
	g.l.Lock()
	if i, e := g.index.NextClear(0); e {
		g.data[i] = *t
		g.index.Set(i)
		tp = &g.data[i]
		g.l.Unlock()
		return
	}
	if g.next == nil {
		g.next = newintGroup(g)
	}
	g.l.Unlock()
	return g.next.Insert(t)
}

func (g *colonyGroupint) Delete(tp *int) {
	if uintptr(unsafe.Pointer(tp)) > g.maxPtr { // hack to determine if a pointer points to this array
		g.next.Delete(tp)
	}
	g.l.Lock()
	for i := 0; i < len(g.data); i++ {
		if tp == &g.data[i] {
			g.index.Clear(uint(i))
			//if !g.index.Any() {
			// TODO: if a group has no more elements, then we should de-allocate it.
			//}
			g.l.Unlock()
			return
		}
	}
	g.l.Unlock()
	if g.next != nil {
		g.next.Delete(tp)
	}
}

type Int16Colony struct {
	entry *colonyGroupint16
}

// NewInt16Colony returns a new colony of ValueInt16's.
func NewInt16Colony() *Int16Colony {
	return &Int16Colony{
		entry: newint16Group(nil),
	}
}

// Iterate sends pointers to all instances of ValueInt16 in the colony to the given channel.
func (c *Int16Colony) Iterate() <-chan *int16 {
	ch := make(chan *int16)
	var wg sync.WaitGroup
	for g := c.entry; g != nil; g = g.next {
		wg.Add(1)
		go func(g *colonyGroupint16) {
			g.l.RLock()
			for i, e := g.index.NextSet(0); e; i, e = g.index.NextSet(i + 1) {
				ch <- &g.data[i]
			}
			g.l.RUnlock()
			wg.Done()
		}(g)
	}
	go func() {
		wg.Wait()
		close(ch)
	}()
	return ch
}

func (c *Int16Colony) Insert(t *int16) (tp *int16) {
	return c.entry.Insert(t)
}

func (c *Int16Colony) Delete(tp *int16) {
	c.entry.Delete(tp)
}

func newint16Group(previous *colonyGroupint16) *colonyGroupint16 {
	var g colonyGroupint16
	if previous != nil {
		g.data = make([]int16, len(previous.data)*2)
		g.index = bitset.New(uint(len(previous.data) * 2))
	} else {
		g.data = make([]int16, 8)
		g.index = bitset.New(8)
	}
	g.next = nil
	g.l = &sync.RWMutex{}
	g.minPtr = uintptr(unsafe.Pointer(&g.data[0]))
	g.maxPtr = uintptr(unsafe.Pointer(&g.data[len(g.data)-1]))
	return &g
}

type colonyGroupint16 struct {
	data     []int16
	index    *bitset.BitSet
	maxPtr   uintptr
	minPtr   uintptr
	next     *colonyGroupint16
	previous *colonyGroupint16

	l *sync.RWMutex
}

func (g *colonyGroupint16) Insert(t *int16) (tp *int16) {
	g.l.Lock()
	if i, e := g.index.NextClear(0); e {
		g.data[i] = *t
		g.index.Set(i)
		tp = &g.data[i]
		g.l.Unlock()
		return
	}
	if g.next == nil {
		g.next = newint16Group(g)
	}
	g.l.Unlock()
	return g.next.Insert(t)
}

func (g *colonyGroupint16) Delete(tp *int16) {
	if uintptr(unsafe.Pointer(tp)) > g.maxPtr { // hack to determine if a pointer points to this array
		g.next.Delete(tp)
	}
	g.l.Lock()
	for i := 0; i < len(g.data); i++ {
		if tp == &g.data[i] {
			g.index.Clear(uint(i))
			//if !g.index.Any() {
			// TODO: if a group has no more elements, then we should de-allocate it.
			//}
			g.l.Unlock()
			return
		}
	}
	g.l.Unlock()
	if g.next != nil {
		g.next.Delete(tp)
	}
}

type Int32Colony struct {
	entry *colonyGroupint32
}

// NewInt32Colony returns a new colony of ValueInt32's.
func NewInt32Colony() *Int32Colony {
	return &Int32Colony{
		entry: newint32Group(nil),
	}
}

// Iterate sends pointers to all instances of ValueInt32 in the colony to the given channel.
func (c *Int32Colony) Iterate() <-chan *int32 {
	ch := make(chan *int32)
	var wg sync.WaitGroup
	for g := c.entry; g != nil; g = g.next {
		wg.Add(1)
		go func(g *colonyGroupint32) {
			g.l.RLock()
			for i, e := g.index.NextSet(0); e; i, e = g.index.NextSet(i + 1) {
				ch <- &g.data[i]
			}
			g.l.RUnlock()
			wg.Done()
		}(g)
	}
	go func() {
		wg.Wait()
		close(ch)
	}()
	return ch
}

func (c *Int32Colony) Insert(t *int32) (tp *int32) {
	return c.entry.Insert(t)
}

func (c *Int32Colony) Delete(tp *int32) {
	c.entry.Delete(tp)
}

func newint32Group(previous *colonyGroupint32) *colonyGroupint32 {
	var g colonyGroupint32
	if previous != nil {
		g.data = make([]int32, len(previous.data)*2)
		g.index = bitset.New(uint(len(previous.data) * 2))
	} else {
		g.data = make([]int32, 8)
		g.index = bitset.New(8)
	}
	g.next = nil
	g.l = &sync.RWMutex{}
	g.minPtr = uintptr(unsafe.Pointer(&g.data[0]))
	g.maxPtr = uintptr(unsafe.Pointer(&g.data[len(g.data)-1]))
	return &g
}

type colonyGroupint32 struct {
	data     []int32
	index    *bitset.BitSet
	maxPtr   uintptr
	minPtr   uintptr
	next     *colonyGroupint32
	previous *colonyGroupint32

	l *sync.RWMutex
}

func (g *colonyGroupint32) Insert(t *int32) (tp *int32) {
	g.l.Lock()
	if i, e := g.index.NextClear(0); e {
		g.data[i] = *t
		g.index.Set(i)
		tp = &g.data[i]
		g.l.Unlock()
		return
	}
	if g.next == nil {
		g.next = newint32Group(g)
	}
	g.l.Unlock()
	return g.next.Insert(t)
}

func (g *colonyGroupint32) Delete(tp *int32) {
	if uintptr(unsafe.Pointer(tp)) > g.maxPtr { // hack to determine if a pointer points to this array
		g.next.Delete(tp)
	}
	g.l.Lock()
	for i := 0; i < len(g.data); i++ {
		if tp == &g.data[i] {
			g.index.Clear(uint(i))
			//if !g.index.Any() {
			// TODO: if a group has no more elements, then we should de-allocate it.
			//}
			g.l.Unlock()
			return
		}
	}
	g.l.Unlock()
	if g.next != nil {
		g.next.Delete(tp)
	}
}

type Int64Colony struct {
	entry *colonyGroupint64
}

// NewInt64Colony returns a new colony of ValueInt64's.
func NewInt64Colony() *Int64Colony {
	return &Int64Colony{
		entry: newint64Group(nil),
	}
}

// Iterate sends pointers to all instances of ValueInt64 in the colony to the given channel.
func (c *Int64Colony) Iterate() <-chan *int64 {
	ch := make(chan *int64)
	var wg sync.WaitGroup
	for g := c.entry; g != nil; g = g.next {
		wg.Add(1)
		go func(g *colonyGroupint64) {
			g.l.RLock()
			for i, e := g.index.NextSet(0); e; i, e = g.index.NextSet(i + 1) {
				ch <- &g.data[i]
			}
			g.l.RUnlock()
			wg.Done()
		}(g)
	}
	go func() {
		wg.Wait()
		close(ch)
	}()
	return ch
}

func (c *Int64Colony) Insert(t *int64) (tp *int64) {
	return c.entry.Insert(t)
}

func (c *Int64Colony) Delete(tp *int64) {
	c.entry.Delete(tp)
}

func newint64Group(previous *colonyGroupint64) *colonyGroupint64 {
	var g colonyGroupint64
	if previous != nil {
		g.data = make([]int64, len(previous.data)*2)
		g.index = bitset.New(uint(len(previous.data) * 2))
	} else {
		g.data = make([]int64, 8)
		g.index = bitset.New(8)
	}
	g.next = nil
	g.l = &sync.RWMutex{}
	g.minPtr = uintptr(unsafe.Pointer(&g.data[0]))
	g.maxPtr = uintptr(unsafe.Pointer(&g.data[len(g.data)-1]))
	return &g
}

type colonyGroupint64 struct {
	data     []int64
	index    *bitset.BitSet
	maxPtr   uintptr
	minPtr   uintptr
	next     *colonyGroupint64
	previous *colonyGroupint64

	l *sync.RWMutex
}

func (g *colonyGroupint64) Insert(t *int64) (tp *int64) {
	g.l.Lock()
	if i, e := g.index.NextClear(0); e {
		g.data[i] = *t
		g.index.Set(i)
		tp = &g.data[i]
		g.l.Unlock()
		return
	}
	if g.next == nil {
		g.next = newint64Group(g)
	}
	g.l.Unlock()
	return g.next.Insert(t)
}

func (g *colonyGroupint64) Delete(tp *int64) {
	if uintptr(unsafe.Pointer(tp)) > g.maxPtr { // hack to determine if a pointer points to this array
		g.next.Delete(tp)
	}
	g.l.Lock()
	for i := 0; i < len(g.data); i++ {
		if tp == &g.data[i] {
			g.index.Clear(uint(i))
			//if !g.index.Any() {
			// TODO: if a group has no more elements, then we should de-allocate it.
			//}
			g.l.Unlock()
			return
		}
	}
	g.l.Unlock()
	if g.next != nil {
		g.next.Delete(tp)
	}
}

type Int8Colony struct {
	entry *colonyGroupint8
}

// NewInt8Colony returns a new colony of ValueInt8's.
func NewInt8Colony() *Int8Colony {
	return &Int8Colony{
		entry: newint8Group(nil),
	}
}

// Iterate sends pointers to all instances of ValueInt8 in the colony to the given channel.
func (c *Int8Colony) Iterate() <-chan *int8 {
	ch := make(chan *int8)
	var wg sync.WaitGroup
	for g := c.entry; g != nil; g = g.next {
		wg.Add(1)
		go func(g *colonyGroupint8) {
			g.l.RLock()
			for i, e := g.index.NextSet(0); e; i, e = g.index.NextSet(i + 1) {
				ch <- &g.data[i]
			}
			g.l.RUnlock()
			wg.Done()
		}(g)
	}
	go func() {
		wg.Wait()
		close(ch)
	}()
	return ch
}

func (c *Int8Colony) Insert(t *int8) (tp *int8) {
	return c.entry.Insert(t)
}

func (c *Int8Colony) Delete(tp *int8) {
	c.entry.Delete(tp)
}

func newint8Group(previous *colonyGroupint8) *colonyGroupint8 {
	var g colonyGroupint8
	if previous != nil {
		g.data = make([]int8, len(previous.data)*2)
		g.index = bitset.New(uint(len(previous.data) * 2))
	} else {
		g.data = make([]int8, 8)
		g.index = bitset.New(8)
	}
	g.next = nil
	g.l = &sync.RWMutex{}
	g.minPtr = uintptr(unsafe.Pointer(&g.data[0]))
	g.maxPtr = uintptr(unsafe.Pointer(&g.data[len(g.data)-1]))
	return &g
}

type colonyGroupint8 struct {
	data     []int8
	index    *bitset.BitSet
	maxPtr   uintptr
	minPtr   uintptr
	next     *colonyGroupint8
	previous *colonyGroupint8

	l *sync.RWMutex
}

func (g *colonyGroupint8) Insert(t *int8) (tp *int8) {
	g.l.Lock()
	if i, e := g.index.NextClear(0); e {
		g.data[i] = *t
		g.index.Set(i)
		tp = &g.data[i]
		g.l.Unlock()
		return
	}
	if g.next == nil {
		g.next = newint8Group(g)
	}
	g.l.Unlock()
	return g.next.Insert(t)
}

func (g *colonyGroupint8) Delete(tp *int8) {
	if uintptr(unsafe.Pointer(tp)) > g.maxPtr { // hack to determine if a pointer points to this array
		g.next.Delete(tp)
	}
	g.l.Lock()
	for i := 0; i < len(g.data); i++ {
		if tp == &g.data[i] {
			g.index.Clear(uint(i))
			//if !g.index.Any() {
			// TODO: if a group has no more elements, then we should de-allocate it.
			//}
			g.l.Unlock()
			return
		}
	}
	g.l.Unlock()
	if g.next != nil {
		g.next.Delete(tp)
	}
}

type RuneColony struct {
	entry *colonyGrouprune
}

// NewRuneColony returns a new colony of ValueRune's.
func NewRuneColony() *RuneColony {
	return &RuneColony{
		entry: newruneGroup(nil),
	}
}

// Iterate sends pointers to all instances of ValueRune in the colony to the given channel.
func (c *RuneColony) Iterate() <-chan *rune {
	ch := make(chan *rune)
	var wg sync.WaitGroup
	for g := c.entry; g != nil; g = g.next {
		wg.Add(1)
		go func(g *colonyGrouprune) {
			g.l.RLock()
			for i, e := g.index.NextSet(0); e; i, e = g.index.NextSet(i + 1) {
				ch <- &g.data[i]
			}
			g.l.RUnlock()
			wg.Done()
		}(g)
	}
	go func() {
		wg.Wait()
		close(ch)
	}()
	return ch
}

func (c *RuneColony) Insert(t *rune) (tp *rune) {
	return c.entry.Insert(t)
}

func (c *RuneColony) Delete(tp *rune) {
	c.entry.Delete(tp)
}

func newruneGroup(previous *colonyGrouprune) *colonyGrouprune {
	var g colonyGrouprune
	if previous != nil {
		g.data = make([]rune, len(previous.data)*2)
		g.index = bitset.New(uint(len(previous.data) * 2))
	} else {
		g.data = make([]rune, 8)
		g.index = bitset.New(8)
	}
	g.next = nil
	g.l = &sync.RWMutex{}
	g.minPtr = uintptr(unsafe.Pointer(&g.data[0]))
	g.maxPtr = uintptr(unsafe.Pointer(&g.data[len(g.data)-1]))
	return &g
}

type colonyGrouprune struct {
	data     []rune
	index    *bitset.BitSet
	maxPtr   uintptr
	minPtr   uintptr
	next     *colonyGrouprune
	previous *colonyGrouprune

	l *sync.RWMutex
}

func (g *colonyGrouprune) Insert(t *rune) (tp *rune) {
	g.l.Lock()
	if i, e := g.index.NextClear(0); e {
		g.data[i] = *t
		g.index.Set(i)
		tp = &g.data[i]
		g.l.Unlock()
		return
	}
	if g.next == nil {
		g.next = newruneGroup(g)
	}
	g.l.Unlock()
	return g.next.Insert(t)
}

func (g *colonyGrouprune) Delete(tp *rune) {
	if uintptr(unsafe.Pointer(tp)) > g.maxPtr { // hack to determine if a pointer points to this array
		g.next.Delete(tp)
	}
	g.l.Lock()
	for i := 0; i < len(g.data); i++ {
		if tp == &g.data[i] {
			g.index.Clear(uint(i))
			//if !g.index.Any() {
			// TODO: if a group has no more elements, then we should de-allocate it.
			//}
			g.l.Unlock()
			return
		}
	}
	g.l.Unlock()
	if g.next != nil {
		g.next.Delete(tp)
	}
}

type StringColony struct {
	entry *colonyGroupstring
}

// NewStringColony returns a new colony of ValueString's.
func NewStringColony() *StringColony {
	return &StringColony{
		entry: newstringGroup(nil),
	}
}

// Iterate sends pointers to all instances of ValueString in the colony to the given channel.
func (c *StringColony) Iterate() <-chan *string {
	ch := make(chan *string)
	var wg sync.WaitGroup
	for g := c.entry; g != nil; g = g.next {
		wg.Add(1)
		go func(g *colonyGroupstring) {
			g.l.RLock()
			for i, e := g.index.NextSet(0); e; i, e = g.index.NextSet(i + 1) {
				ch <- &g.data[i]
			}
			g.l.RUnlock()
			wg.Done()
		}(g)
	}
	go func() {
		wg.Wait()
		close(ch)
	}()
	return ch
}

func (c *StringColony) Insert(t *string) (tp *string) {
	return c.entry.Insert(t)
}

func (c *StringColony) Delete(tp *string) {
	c.entry.Delete(tp)
}

func newstringGroup(previous *colonyGroupstring) *colonyGroupstring {
	var g colonyGroupstring
	if previous != nil {
		g.data = make([]string, len(previous.data)*2)
		g.index = bitset.New(uint(len(previous.data) * 2))
	} else {
		g.data = make([]string, 8)
		g.index = bitset.New(8)
	}
	g.next = nil
	g.l = &sync.RWMutex{}
	g.minPtr = uintptr(unsafe.Pointer(&g.data[0]))
	g.maxPtr = uintptr(unsafe.Pointer(&g.data[len(g.data)-1]))
	return &g
}

type colonyGroupstring struct {
	data     []string
	index    *bitset.BitSet
	maxPtr   uintptr
	minPtr   uintptr
	next     *colonyGroupstring
	previous *colonyGroupstring

	l *sync.RWMutex
}

func (g *colonyGroupstring) Insert(t *string) (tp *string) {
	g.l.Lock()
	if i, e := g.index.NextClear(0); e {
		g.data[i] = *t
		g.index.Set(i)
		tp = &g.data[i]
		g.l.Unlock()
		return
	}
	if g.next == nil {
		g.next = newstringGroup(g)
	}
	g.l.Unlock()
	return g.next.Insert(t)
}

func (g *colonyGroupstring) Delete(tp *string) {
	if uintptr(unsafe.Pointer(tp)) > g.maxPtr { // hack to determine if a pointer points to this array
		g.next.Delete(tp)
	}
	g.l.Lock()
	for i := 0; i < len(g.data); i++ {
		if tp == &g.data[i] {
			g.index.Clear(uint(i))
			//if !g.index.Any() {
			// TODO: if a group has no more elements, then we should de-allocate it.
			//}
			g.l.Unlock()
			return
		}
	}
	g.l.Unlock()
	if g.next != nil {
		g.next.Delete(tp)
	}
}

type UintColony struct {
	entry *colonyGroupuint
}

// NewUintColony returns a new colony of ValueUint's.
func NewUintColony() *UintColony {
	return &UintColony{
		entry: newuintGroup(nil),
	}
}

// Iterate sends pointers to all instances of ValueUint in the colony to the given channel.
func (c *UintColony) Iterate() <-chan *uint {
	ch := make(chan *uint)
	var wg sync.WaitGroup
	for g := c.entry; g != nil; g = g.next {
		wg.Add(1)
		go func(g *colonyGroupuint) {
			g.l.RLock()
			for i, e := g.index.NextSet(0); e; i, e = g.index.NextSet(i + 1) {
				ch <- &g.data[i]
			}
			g.l.RUnlock()
			wg.Done()
		}(g)
	}
	go func() {
		wg.Wait()
		close(ch)
	}()
	return ch
}

func (c *UintColony) Insert(t *uint) (tp *uint) {
	return c.entry.Insert(t)
}

func (c *UintColony) Delete(tp *uint) {
	c.entry.Delete(tp)
}

func newuintGroup(previous *colonyGroupuint) *colonyGroupuint {
	var g colonyGroupuint
	if previous != nil {
		g.data = make([]uint, len(previous.data)*2)
		g.index = bitset.New(uint(len(previous.data) * 2))
	} else {
		g.data = make([]uint, 8)
		g.index = bitset.New(8)
	}
	g.next = nil
	g.l = &sync.RWMutex{}
	g.minPtr = uintptr(unsafe.Pointer(&g.data[0]))
	g.maxPtr = uintptr(unsafe.Pointer(&g.data[len(g.data)-1]))
	return &g
}

type colonyGroupuint struct {
	data     []uint
	index    *bitset.BitSet
	maxPtr   uintptr
	minPtr   uintptr
	next     *colonyGroupuint
	previous *colonyGroupuint

	l *sync.RWMutex
}

func (g *colonyGroupuint) Insert(t *uint) (tp *uint) {
	g.l.Lock()
	if i, e := g.index.NextClear(0); e {
		g.data[i] = *t
		g.index.Set(i)
		tp = &g.data[i]
		g.l.Unlock()
		return
	}
	if g.next == nil {
		g.next = newuintGroup(g)
	}
	g.l.Unlock()
	return g.next.Insert(t)
}

func (g *colonyGroupuint) Delete(tp *uint) {
	if uintptr(unsafe.Pointer(tp)) > g.maxPtr { // hack to determine if a pointer points to this array
		g.next.Delete(tp)
	}
	g.l.Lock()
	for i := 0; i < len(g.data); i++ {
		if tp == &g.data[i] {
			g.index.Clear(uint(i))
			//if !g.index.Any() {
			// TODO: if a group has no more elements, then we should de-allocate it.
			//}
			g.l.Unlock()
			return
		}
	}
	g.l.Unlock()
	if g.next != nil {
		g.next.Delete(tp)
	}
}

type Uint16Colony struct {
	entry *colonyGroupuint16
}

// NewUint16Colony returns a new colony of ValueUint16's.
func NewUint16Colony() *Uint16Colony {
	return &Uint16Colony{
		entry: newuint16Group(nil),
	}
}

// Iterate sends pointers to all instances of ValueUint16 in the colony to the given channel.
func (c *Uint16Colony) Iterate() <-chan *uint16 {
	ch := make(chan *uint16)
	var wg sync.WaitGroup
	for g := c.entry; g != nil; g = g.next {
		wg.Add(1)
		go func(g *colonyGroupuint16) {
			g.l.RLock()
			for i, e := g.index.NextSet(0); e; i, e = g.index.NextSet(i + 1) {
				ch <- &g.data[i]
			}
			g.l.RUnlock()
			wg.Done()
		}(g)
	}
	go func() {
		wg.Wait()
		close(ch)
	}()
	return ch
}

func (c *Uint16Colony) Insert(t *uint16) (tp *uint16) {
	return c.entry.Insert(t)
}

func (c *Uint16Colony) Delete(tp *uint16) {
	c.entry.Delete(tp)
}

func newuint16Group(previous *colonyGroupuint16) *colonyGroupuint16 {
	var g colonyGroupuint16
	if previous != nil {
		g.data = make([]uint16, len(previous.data)*2)
		g.index = bitset.New(uint(len(previous.data) * 2))
	} else {
		g.data = make([]uint16, 8)
		g.index = bitset.New(8)
	}
	g.next = nil
	g.l = &sync.RWMutex{}
	g.minPtr = uintptr(unsafe.Pointer(&g.data[0]))
	g.maxPtr = uintptr(unsafe.Pointer(&g.data[len(g.data)-1]))
	return &g
}

type colonyGroupuint16 struct {
	data     []uint16
	index    *bitset.BitSet
	maxPtr   uintptr
	minPtr   uintptr
	next     *colonyGroupuint16
	previous *colonyGroupuint16

	l *sync.RWMutex
}

func (g *colonyGroupuint16) Insert(t *uint16) (tp *uint16) {
	g.l.Lock()
	if i, e := g.index.NextClear(0); e {
		g.data[i] = *t
		g.index.Set(i)
		tp = &g.data[i]
		g.l.Unlock()
		return
	}
	if g.next == nil {
		g.next = newuint16Group(g)
	}
	g.l.Unlock()
	return g.next.Insert(t)
}

func (g *colonyGroupuint16) Delete(tp *uint16) {
	if uintptr(unsafe.Pointer(tp)) > g.maxPtr { // hack to determine if a pointer points to this array
		g.next.Delete(tp)
	}
	g.l.Lock()
	for i := 0; i < len(g.data); i++ {
		if tp == &g.data[i] {
			g.index.Clear(uint(i))
			//if !g.index.Any() {
			// TODO: if a group has no more elements, then we should de-allocate it.
			//}
			g.l.Unlock()
			return
		}
	}
	g.l.Unlock()
	if g.next != nil {
		g.next.Delete(tp)
	}
}

type Uint32Colony struct {
	entry *colonyGroupuint32
}

// NewUint32Colony returns a new colony of ValueUint32's.
func NewUint32Colony() *Uint32Colony {
	return &Uint32Colony{
		entry: newuint32Group(nil),
	}
}

// Iterate sends pointers to all instances of ValueUint32 in the colony to the given channel.
func (c *Uint32Colony) Iterate() <-chan *uint32 {
	ch := make(chan *uint32)
	var wg sync.WaitGroup
	for g := c.entry; g != nil; g = g.next {
		wg.Add(1)
		go func(g *colonyGroupuint32) {
			g.l.RLock()
			for i, e := g.index.NextSet(0); e; i, e = g.index.NextSet(i + 1) {
				ch <- &g.data[i]
			}
			g.l.RUnlock()
			wg.Done()
		}(g)
	}
	go func() {
		wg.Wait()
		close(ch)
	}()
	return ch
}

func (c *Uint32Colony) Insert(t *uint32) (tp *uint32) {
	return c.entry.Insert(t)
}

func (c *Uint32Colony) Delete(tp *uint32) {
	c.entry.Delete(tp)
}

func newuint32Group(previous *colonyGroupuint32) *colonyGroupuint32 {
	var g colonyGroupuint32
	if previous != nil {
		g.data = make([]uint32, len(previous.data)*2)
		g.index = bitset.New(uint(len(previous.data) * 2))
	} else {
		g.data = make([]uint32, 8)
		g.index = bitset.New(8)
	}
	g.next = nil
	g.l = &sync.RWMutex{}
	g.minPtr = uintptr(unsafe.Pointer(&g.data[0]))
	g.maxPtr = uintptr(unsafe.Pointer(&g.data[len(g.data)-1]))
	return &g
}

type colonyGroupuint32 struct {
	data     []uint32
	index    *bitset.BitSet
	maxPtr   uintptr
	minPtr   uintptr
	next     *colonyGroupuint32
	previous *colonyGroupuint32

	l *sync.RWMutex
}

func (g *colonyGroupuint32) Insert(t *uint32) (tp *uint32) {
	g.l.Lock()
	if i, e := g.index.NextClear(0); e {
		g.data[i] = *t
		g.index.Set(i)
		tp = &g.data[i]
		g.l.Unlock()
		return
	}
	if g.next == nil {
		g.next = newuint32Group(g)
	}
	g.l.Unlock()
	return g.next.Insert(t)
}

func (g *colonyGroupuint32) Delete(tp *uint32) {
	if uintptr(unsafe.Pointer(tp)) > g.maxPtr { // hack to determine if a pointer points to this array
		g.next.Delete(tp)
	}
	g.l.Lock()
	for i := 0; i < len(g.data); i++ {
		if tp == &g.data[i] {
			g.index.Clear(uint(i))
			//if !g.index.Any() {
			// TODO: if a group has no more elements, then we should de-allocate it.
			//}
			g.l.Unlock()
			return
		}
	}
	g.l.Unlock()
	if g.next != nil {
		g.next.Delete(tp)
	}
}

type Uint64Colony struct {
	entry *colonyGroupuint64
}

// NewUint64Colony returns a new colony of ValueUint64's.
func NewUint64Colony() *Uint64Colony {
	return &Uint64Colony{
		entry: newuint64Group(nil),
	}
}

// Iterate sends pointers to all instances of ValueUint64 in the colony to the given channel.
func (c *Uint64Colony) Iterate() <-chan *uint64 {
	ch := make(chan *uint64)
	var wg sync.WaitGroup
	for g := c.entry; g != nil; g = g.next {
		wg.Add(1)
		go func(g *colonyGroupuint64) {
			g.l.RLock()
			for i, e := g.index.NextSet(0); e; i, e = g.index.NextSet(i + 1) {
				ch <- &g.data[i]
			}
			g.l.RUnlock()
			wg.Done()
		}(g)
	}
	go func() {
		wg.Wait()
		close(ch)
	}()
	return ch
}

func (c *Uint64Colony) Insert(t *uint64) (tp *uint64) {
	return c.entry.Insert(t)
}

func (c *Uint64Colony) Delete(tp *uint64) {
	c.entry.Delete(tp)
}

func newuint64Group(previous *colonyGroupuint64) *colonyGroupuint64 {
	var g colonyGroupuint64
	if previous != nil {
		g.data = make([]uint64, len(previous.data)*2)
		g.index = bitset.New(uint(len(previous.data) * 2))
	} else {
		g.data = make([]uint64, 8)
		g.index = bitset.New(8)
	}
	g.next = nil
	g.l = &sync.RWMutex{}
	g.minPtr = uintptr(unsafe.Pointer(&g.data[0]))
	g.maxPtr = uintptr(unsafe.Pointer(&g.data[len(g.data)-1]))
	return &g
}

type colonyGroupuint64 struct {
	data     []uint64
	index    *bitset.BitSet
	maxPtr   uintptr
	minPtr   uintptr
	next     *colonyGroupuint64
	previous *colonyGroupuint64

	l *sync.RWMutex
}

func (g *colonyGroupuint64) Insert(t *uint64) (tp *uint64) {
	g.l.Lock()
	if i, e := g.index.NextClear(0); e {
		g.data[i] = *t
		g.index.Set(i)
		tp = &g.data[i]
		g.l.Unlock()
		return
	}
	if g.next == nil {
		g.next = newuint64Group(g)
	}
	g.l.Unlock()
	return g.next.Insert(t)
}

func (g *colonyGroupuint64) Delete(tp *uint64) {
	if uintptr(unsafe.Pointer(tp)) > g.maxPtr { // hack to determine if a pointer points to this array
		g.next.Delete(tp)
	}
	g.l.Lock()
	for i := 0; i < len(g.data); i++ {
		if tp == &g.data[i] {
			g.index.Clear(uint(i))
			//if !g.index.Any() {
			// TODO: if a group has no more elements, then we should de-allocate it.
			//}
			g.l.Unlock()
			return
		}
	}
	g.l.Unlock()
	if g.next != nil {
		g.next.Delete(tp)
	}
}

type Uint8Colony struct {
	entry *colonyGroupuint8
}

// NewUint8Colony returns a new colony of ValueUint8's.
func NewUint8Colony() *Uint8Colony {
	return &Uint8Colony{
		entry: newuint8Group(nil),
	}
}

// Iterate sends pointers to all instances of ValueUint8 in the colony to the given channel.
func (c *Uint8Colony) Iterate() <-chan *uint8 {
	ch := make(chan *uint8)
	var wg sync.WaitGroup
	for g := c.entry; g != nil; g = g.next {
		wg.Add(1)
		go func(g *colonyGroupuint8) {
			g.l.RLock()
			for i, e := g.index.NextSet(0); e; i, e = g.index.NextSet(i + 1) {
				ch <- &g.data[i]
			}
			g.l.RUnlock()
			wg.Done()
		}(g)
	}
	go func() {
		wg.Wait()
		close(ch)
	}()
	return ch
}

func (c *Uint8Colony) Insert(t *uint8) (tp *uint8) {
	return c.entry.Insert(t)
}

func (c *Uint8Colony) Delete(tp *uint8) {
	c.entry.Delete(tp)
}

func newuint8Group(previous *colonyGroupuint8) *colonyGroupuint8 {
	var g colonyGroupuint8
	if previous != nil {
		g.data = make([]uint8, len(previous.data)*2)
		g.index = bitset.New(uint(len(previous.data) * 2))
	} else {
		g.data = make([]uint8, 8)
		g.index = bitset.New(8)
	}
	g.next = nil
	g.l = &sync.RWMutex{}
	g.minPtr = uintptr(unsafe.Pointer(&g.data[0]))
	g.maxPtr = uintptr(unsafe.Pointer(&g.data[len(g.data)-1]))
	return &g
}

type colonyGroupuint8 struct {
	data     []uint8
	index    *bitset.BitSet
	maxPtr   uintptr
	minPtr   uintptr
	next     *colonyGroupuint8
	previous *colonyGroupuint8

	l *sync.RWMutex
}

func (g *colonyGroupuint8) Insert(t *uint8) (tp *uint8) {
	g.l.Lock()
	if i, e := g.index.NextClear(0); e {
		g.data[i] = *t
		g.index.Set(i)
		tp = &g.data[i]
		g.l.Unlock()
		return
	}
	if g.next == nil {
		g.next = newuint8Group(g)
	}
	g.l.Unlock()
	return g.next.Insert(t)
}

func (g *colonyGroupuint8) Delete(tp *uint8) {
	if uintptr(unsafe.Pointer(tp)) > g.maxPtr { // hack to determine if a pointer points to this array
		g.next.Delete(tp)
	}
	g.l.Lock()
	for i := 0; i < len(g.data); i++ {
		if tp == &g.data[i] {
			g.index.Clear(uint(i))
			//if !g.index.Any() {
			// TODO: if a group has no more elements, then we should de-allocate it.
			//}
			g.l.Unlock()
			return
		}
	}
	g.l.Unlock()
	if g.next != nil {
		g.next.Delete(tp)
	}
}

type UintptrColony struct {
	entry *colonyGroupuintptr
}

// NewUintptrColony returns a new colony of ValueUintptr's.
func NewUintptrColony() *UintptrColony {
	return &UintptrColony{
		entry: newuintptrGroup(nil),
	}
}

// Iterate sends pointers to all instances of ValueUintptr in the colony to the given channel.
func (c *UintptrColony) Iterate() <-chan *uintptr {
	ch := make(chan *uintptr)
	var wg sync.WaitGroup
	for g := c.entry; g != nil; g = g.next {
		wg.Add(1)
		go func(g *colonyGroupuintptr) {
			g.l.RLock()
			for i, e := g.index.NextSet(0); e; i, e = g.index.NextSet(i + 1) {
				ch <- &g.data[i]
			}
			g.l.RUnlock()
			wg.Done()
		}(g)
	}
	go func() {
		wg.Wait()
		close(ch)
	}()
	return ch
}

func (c *UintptrColony) Insert(t *uintptr) (tp *uintptr) {
	return c.entry.Insert(t)
}

func (c *UintptrColony) Delete(tp *uintptr) {
	c.entry.Delete(tp)
}

func newuintptrGroup(previous *colonyGroupuintptr) *colonyGroupuintptr {
	var g colonyGroupuintptr
	if previous != nil {
		g.data = make([]uintptr, len(previous.data)*2)
		g.index = bitset.New(uint(len(previous.data) * 2))
	} else {
		g.data = make([]uintptr, 8)
		g.index = bitset.New(8)
	}
	g.next = nil
	g.l = &sync.RWMutex{}
	g.minPtr = uintptr(unsafe.Pointer(&g.data[0]))
	g.maxPtr = uintptr(unsafe.Pointer(&g.data[len(g.data)-1]))
	return &g
}

type colonyGroupuintptr struct {
	data     []uintptr
	index    *bitset.BitSet
	maxPtr   uintptr
	minPtr   uintptr
	next     *colonyGroupuintptr
	previous *colonyGroupuintptr

	l *sync.RWMutex
}

func (g *colonyGroupuintptr) Insert(t *uintptr) (tp *uintptr) {
	g.l.Lock()
	if i, e := g.index.NextClear(0); e {
		g.data[i] = *t
		g.index.Set(i)
		tp = &g.data[i]
		g.l.Unlock()
		return
	}
	if g.next == nil {
		g.next = newuintptrGroup(g)
	}
	g.l.Unlock()
	return g.next.Insert(t)
}

func (g *colonyGroupuintptr) Delete(tp *uintptr) {
	if uintptr(unsafe.Pointer(tp)) > g.maxPtr { // hack to determine if a pointer points to this array
		g.next.Delete(tp)
	}
	g.l.Lock()
	for i := 0; i < len(g.data); i++ {
		if tp == &g.data[i] {
			g.index.Clear(uint(i))
			//if !g.index.Any() {
			// TODO: if a group has no more elements, then we should de-allocate it.
			//}
			g.l.Unlock()
			return
		}
	}
	g.l.Unlock()
	if g.next != nil {
		g.next.Delete(tp)
	}
}
